{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replication from White Matter Network Architecture Guides Direct Electrical Stimulation through Optimal State Transitions\n",
    "Direct electrical brain stimulation is useful treatment for some neurological disorders (most famously, Parkinson's). However, we still don't really have a good way of predicting how stimulation at single region will influnce the rest of the brain. Here, we hypothesize that input from stimulation will spread linearly along white matter tracts to impact brain activity at distant regions. We use a dataset of combined iEEG, DWI, and stimulation data to simulate stimulation based on this hypothesis.\n",
    "\n",
    "Data consist of one DWi structural adjacency matrix per dataset, and variable number of stimulation trials. Each stimulation trial includes the brain state before and after stimulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'Electrode_ROI', 'Post_Freq_State', 'Post_Stim_Prob', 'Pre_Freq_State', 'Pre_Stim_Prob', 'Stim_Amp', 'Stim_Duration', 'Stim_Freq', 'Stim_Loc_Idx', 'Struct_Adj'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "workdir = '/Users/stiso/Documents/Code/test_data/'\n",
    "subj = ['R1170J_1.PS2_1_set1', 'R1173J.PS2_1_set1', 'R1170J_1.PS2_1_set2',\n",
    "        'R1173J.sham_PS2_1_set1', 'R1170J_1.sham_PS2_1_set1', 'R1170J_1.sham_PS2_1_set2'];\n",
    "dat = sio.loadmat(f'{workdir}Trajectory_Data.{subj[0]}.mat')\n",
    "dat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters\n",
    "# these were the parameters were used in the the paper. they were chosen to minimuze error, \n",
    "# reults were validated in 2 additional parameter sets\n",
    "\n",
    "# balance between minimizing energy or minimizing distance from target state\n",
    "rho = .2  \n",
    "# time to go from initial to target state\n",
    "T = .7      \n",
    "# the number of time points the code spits out: T * 1000 + 1\n",
    "nTime = 701 \n",
    "gamma = 4\n",
    "# to try and simulate stimuluation, we're gonna weight the B matrix\n",
    "B_mu = .0005 \n",
    "B_sigma = .00005\n",
    "scale = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does it take more energy to get to post-stimulation state, or a  sham stimulation state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing A for a continuous-time system\n",
      "Normalizing A for a continuous-time system\n",
      "Normalizing A for a continuous-time system\n"
     ]
    }
   ],
   "source": [
    "from network_control.utils import matrix_normalization\n",
    "from network_control.energies import optimal_input\n",
    "\n",
    "# intiialize final data strcutre\n",
    "energies = pd.DataFrame(columns=['energy', 'condition', 'subject', 'trial', 'error'])\n",
    "\n",
    "for i,s in enumerate(subj):\n",
    "    # load in data\n",
    "    dat = sio.loadmat(f'{workdir}Trajectory_Data.{s}.mat')\n",
    "    \n",
    "    # stim or sham?\n",
    "    if 'sham' in s:\n",
    "        cond = 'sham'\n",
    "    else:\n",
    "        cond = 'stim'\n",
    "    \n",
    "    # subject specific constants\n",
    "    # number of stim trials for this set\n",
    "    nTrial = np.size(dat['Post_Freq_State'],0)\n",
    "    # number of nodes/regions in the atlas we are using\n",
    "    nROI = np.size(dat['Post_Freq_State'],1) \n",
    "    # number of bands\n",
    "    nFreq = np.size(dat['Post_Freq_State'],2)\n",
    "    # these are the regions with contacts\n",
    "    elec_idx = np.sum(dat['Post_Freq_State'][:,:,0],0) != 0 \n",
    "    ROI_idx = [not x for x in elec_idx]\n",
    "    # number of contacts\n",
    "    nElec = sum(elec_idx)\n",
    "    # stim contacts\n",
    "    stim_idx = [x[0][0] for x in dat['Stim_Loc_Idx']]\n",
    "\n",
    "    # which regions we want to constrain the state of\n",
    "    S = np.eye(nROI)\n",
    "    \n",
    "    # scale A matrix (continuous)\n",
    "    # this variable will be the same for both datasets\n",
    "    A = dat['Struct_Adj'] \n",
    "    A = matrix_normalization(A, c=gamma, version='continuous')\n",
    "\n",
    "    # get optimal input and trajectory for each trial\n",
    "    \n",
    "    for t in range(nTrial):\n",
    "        # get stim contacts\n",
    "        e = stim_idx[t]\n",
    "        \n",
    "        # set B matrix - ultimate goal is to have the majority of input be at the stim elecs\n",
    "        # first, we set small input everywhere\n",
    "        B = np.eye(nROI) * np.random.normal(loc=B_mu, scale=B_sigma, size=(1, nROI)) \n",
    "        # then we add 0s to all the areas whos activity we know\n",
    "        B[elec_idx,elec_idx] = 0 \n",
    "        # then, we add big numbers to the stim elecs\n",
    "        for c in e:\n",
    "            B[c,c] = 1\n",
    "\n",
    "        # get states\n",
    "        x0 = np.squeeze(dat['Pre_Freq_State'][t,:,:])\n",
    "        xf = np.squeeze(dat['Post_Freq_State'][t,:,:])\n",
    "\n",
    "        # add 1s to regions without elecs\n",
    "        x0[ROI_idx,:] = 1\n",
    "        xf[ROI_idx,:] = 1\n",
    "\n",
    "        # concatenate across frequency bands\n",
    "        u = np.zeros((nROI,nTime,nFreq))\n",
    "        err = np.zeros((1,nFreq))\n",
    "        for f in range(nFreq):\n",
    "            _,curr_u, curr_err = optimal_input(A,T,B,x0[:,f],xf[:,f],rho,S)\n",
    "\n",
    "            curr_u = curr_u.T\n",
    "            err[:,f] = curr_err\n",
    "\n",
    "            u[:,:,f] = curr_u\n",
    "        \n",
    "        # get summary of optimal input\n",
    "        # we incorporated the B matrix into our input summary because of the weighting\n",
    "        # we use the term energy to be consistent with other literature, but in some sense this is a different summary statistic\n",
    "        u = sum(np.linalg.norm(u.T*np.diag(B),axis=(0,2)))/nTime\n",
    "\n",
    "        # average over frequencies\n",
    "        err = np.mean(err)\n",
    "\n",
    "\n",
    "        # add to data frame (averaged over freqs)\n",
    "        curr = pd.DataFrame({'energy':[np.mean(u)], \n",
    "                                  'condition':[cond], \n",
    "                                  'subject':[s.replace('sham_','')], \n",
    "                                  'trial':[t], \n",
    "                                  'error':[err]})\n",
    "        energies = pd.concat([energies,curr])\n",
    "\n",
    "energies['log_eng'] = np.log(energies['energy']) \n",
    "energies['log_err'] = np.log(energies['error'])   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we get similar errors for each condition, so any differences are not being driven by having more accurate calculations for stim vs sham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(8,6))\n",
    "sns.histplot(energies, x='log_err', hue='condition', stat='probability', ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this plot will look a little different from the original paper because we're plotting CI instead of SE\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,6))\n",
    "sns.pointplot(data=energies, y='log_eng', x = 'condition', hue = 'subject',  ax=ax, size=200)\n",
    "#ax.set(yscale='log')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
